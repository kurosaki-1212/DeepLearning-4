{"cells":[{"cell_type":"code","source":["!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n","!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n","!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n","!pip install mecab-python3 > /dev/null\n","\n","# シンボリックリンクによるエラー回避\n","!ln -s /etc/mecabrc /usr/local/etc/mecabrc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCKsnVSjYR5K","outputId":"3e3b8854-c586-4512-bbff-697efde7939d","executionInfo":{"status":"ok","timestamp":1654822025950,"user_tz":-540,"elapsed":77369,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}}},"id":"QCKsnVSjYR5K","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mecab-ipadic-neologd'...\n","remote: Enumerating objects: 75, done.\u001b[K\n","remote: Counting objects: 100% (75/75), done.\u001b[K\n","remote: Compressing objects: 100% (74/74), done.\u001b[K\n","remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (75/75), done.\n"]}]},{"cell_type":"code","source":["# パスの確認↓\n","!echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TciUYWZ9YbfE","outputId":"109f19a4-0399-42e2-b895-73aa8207c974","executionInfo":{"status":"ok","timestamp":1654822418369,"user_tz":-540,"elapsed":367,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}}},"id":"TciUYWZ9YbfE","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n"]}]},{"cell_type":"markdown","id":"f0ac997c","metadata":{"id":"f0ac997c"},"source":["①スパムテキストのダウンロード\n","https://github.com/kujirahand/spam-database-ja"]},{"cell_type":"markdown","id":"38bc7199","metadata":{"id":"38bc7199"},"source":["②Livedoorニュースコーパス\n","https://www.rondhuit.com/download.html#ldcc\n","\n","→ gzデータを展開するアプリが必要なため、Teamsから「livedoornews.zip」をDLしてください。"]},{"cell_type":"markdown","source":["③ ①と②のファイルをColab環境にアップロード"],"metadata":{"id":"Qmr8N4fjWIAR"},"id":"Qmr8N4fjWIAR"},{"cell_type":"markdown","source":["④ アップロードした①と②をColab上で展開（unzip）する。\n","\n","ヒント：効果測定対策練習問題／問2"],"metadata":{"id":"aeOkvXytWQTF"},"id":"aeOkvXytWQTF"},{"cell_type":"code","source":["!unzip 'spam-sjis.zip'"],"metadata":{"id":"rhAURhbFW3vm"},"id":"rhAURhbFW3vm","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip 'livedoornews.zip'"],"metadata":{"id":"V6103WJMWe96"},"id":"V6103WJMWe96","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["⑤ P237の作業を行う。\n","\n","展開済みのフォルダ「livedoornews」のフォルダ名を「ok」に変更する"],"metadata":{"id":"WdRGE6-qXwjA"},"id":"WdRGE6-qXwjA"},{"cell_type":"markdown","source":["⑥ P237の作業を行う\n","\n","展開済みの「spam-sjis」フォルダの中から、「ok」フォルダと同数程度のファイルを「spam」という新規フォルダに移動、もしくはコピーする。\n","\n","ヒント：P177、glob\n","\n","ファイルを移動\n","https://note.nkmk.me/python-shutil-move/"],"metadata":{"id":"LpCEfTzae5I-"},"id":"LpCEfTzae5I-"},{"cell_type":"code","source":[""],"metadata":{"id":"YCE3Xab9gAOR"},"id":"YCE3Xab9gAOR","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["spamデータの「00001.txt」はエンコードのエラーが回避できないので削除しておく"],"metadata":{"id":"rXmmhZr4x9mT"},"id":"rXmmhZr4x9mT"},{"cell_type":"markdown","source":["# 以下のソースコードは気が向いたら試してみる程度でOK\n","\n","※ちょっと時間がかかります。"],"metadata":{"id":"YfHYN3Pz8AZ5"},"id":"YfHYN3Pz8AZ5"},{"cell_type":"code","execution_count":7,"id":"093f0f35","metadata":{"id":"093f0f35","executionInfo":{"status":"ok","timestamp":1654824308898,"user_tz":-540,"elapsed":264,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}}},"outputs":[],"source":["# 全てのテキストを巡回して単語データベースを作成する\n","import os, glob\n","import MeCab\n","import numpy as np\n","import pickle\n","\n","# 保存ファイル名\n","savefile = \"./ok-spam.pickle\"\n","# MeCabの準備\n","tagger = MeCab.Tagger('/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n","# 変数の準備\n","word_dic = {\"__id\": 0} # 単語辞書\n","files = [] # 読み込んだ単語データを追加する\n","\n","# 指定したディレクトリ内のファイル一覧を読む\n","def read_files(dir, enccd, label):\n","    # テキストファイルの一覧を得る\n","    files = glob.glob(dir + '/*.txt')\n","    for f in files:\n","        read_file(f,enccd, label)\n","\n","# ファイルを読む\n","def read_file(filename, enccd,label):\n","    words = []\n","    # ファイルの内容を読む★\n","    print('filename',filename)\n","    with open(filename, \"rt\", encoding=enccd) as f:\n","        text = f.read()\n","    files.append({\n","        \"label\": label,\n","        \"words\": text_to_ids(text)\n","    })\n","\n","# テキストを単語IDのリストに変換\n","def text_to_ids(text):\n","    # 形態素解析\n","    word_s = tagger.parse(text)\n","    words = []\n","    # 単語を辞書に登録\n","    for line in word_s.split(\"\\n\"):\n","        \n","        if line == 'EOS' or line == '': continue\n","        word = line.split(\"\\t\")[0]\n","\n","        hinsi = line.split(\"\\t\")[1].split(',')[0]\n","        hinsi2 = line.split(\"\\t\")[1].split(',')[1]\n","        org = line.split('\\t')[1].split(',')[6]\n","\n","\n","        # 助詞・助動詞・記号・数字は捨てる\n","        if not (hinsi in ['名詞', '動詞', '形容詞']): \n","            continue\n","        if hinsi == '名詞' and hinsi2 == '数詞': continue\n","        # 単語をidに変換\n","        id = word_to_id(org)\n","\n","        words.append(id)\n","    return words\n","\n","# 単語をidに変換\n","def word_to_id(word):\n","\n","    # 単語が辞書に登録されているか？\n","    if not (word in word_dic):\n","        # 登録されていないので新たにIDを割り振る\n","        id = word_dic[\"__id\"]\n","        word_dic[\"__id\"] += 1\n","        word_dic[word] = id\n","    else:\n","        # 既存の単語IDを返す\n","        id = word_dic[word]\n","\n","    return id\n","\n","# 単語の頻出頻度のデータを作る\n","def make_freq_data_allfiles():\n","    y = []\n","    x = []\n","    for f in files:\n","        y.append(f['label'])\n","        x.append(make_freq_data(f['words']))\n","    return y, x\n","\n","def make_freq_data(words):\n","    # 単語の出現回数を調べる\n","    cnt = 0\n","    dat = np.zeros(word_dic[\"__id\"], 'float')\n","    for w in words:\n","        dat[w] += 1\n","        cnt += 1\n","    # 回数を出現頻度に直す\n","    dat = dat / cnt\n","    return dat\n","\n"]},{"cell_type":"code","source":["read_files(\"ok\",\"utf-8\", 0)\n","read_files(\"spam\",\"shift-jis\",1)\n","y, x = make_freq_data_allfiles()\n","# ファイルにデータを保存\n","pickle.dump([y, x, word_dic], open(savefile, 'wb'))\n","print(\"単語頻出データ作成完了\")"],"metadata":{"id":"jI4P736kcDdG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654824847324,"user_tz":-540,"elapsed":300,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}},"outputId":"4a9d16a4-c732-4281-e50e-5c5dc6d717e9"},"id":"jI4P736kcDdG","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["単語頻出データ作成完了\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"AK_8f3QX2oBv"},"id":"AK_8f3QX2oBv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# データファイルの読込\n","data_file = \"./ok-spam.pickle\"\n","save_file = \"./ok-spam-model.pickle\"\n","data = pickle.load(open(data_file, \"rb\"))\n","y = data[0] # ラベル\n","x = data[1] # 単語の出現頻度\n"],"metadata":{"id":"EPMbfqd7yatY","executionInfo":{"status":"ok","timestamp":1654825765262,"user_tz":-540,"elapsed":250,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}}},"id":"EPMbfqd7yatY","execution_count":13,"outputs":[]},{"cell_type":"code","source":["\n","# 100回、学習とテストを繰り返す\n","count = 100\n","rate = 0\n","for i in range(count):\n","    # データを学習用とテスト用に分割\n","    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n","    # 学習する\n","    model = GaussianNB()\n","    model.fit(x_train, y_train)\n","    # 評価する\n","    y_pred = model.predict(x_test)\n","    acc = accuracy_score(y_test, y_pred)\n","    # 評価結果が良ければモデルを保存\n","    if acc > 0.94: pickle.dump(model, open(save_file, \"wb\"))\n","    print(acc)\n","    rate += acc\n","# 平均値を表示\n","print(\"----\")\n","print(\"average=\", rate / count)\n","\n"],"metadata":{"id":"cj7oAIfDyICx","colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"status":"error","timestamp":1654825775925,"user_tz":-540,"elapsed":259,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}},"outputId":"7431afbe-54b3-4bfe-b388-27dff1993e42"},"id":"cj7oAIfDyICx","execution_count":15,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-b60e0a9188b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# データを学習用とテスト用に分割\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 学習する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."]}]},{"cell_type":"code","source":["import pickle\n","import MeCab\n","import numpy as np\n","from sklearn.naive_bayes import GaussianNB\n","\n","# テストするテキスト\n","test_text1 = \"\"\"\n","会社から支給されているiPhoneの調子が悪いのです。\n","修理に出すので、しばらくはアプリのテストができません。\n","\"\"\"\n","test_text2 = \"\"\"\n","億万長者になる方法を教えます。\n","すぐに以下のアドレスに返信して。\n","\"\"\"\n","# ファイル名\n","data_file = \"./ok-spam.pickle\"\n","model_file = \"./ok-spam-model.pickle\"\n","label_names = ['OK', 'SPAM']\n","# 単語辞書を読み出す\n","data = pickle.load(open(data_file, \"rb\"))\n","word_dic = data[2]\n","# MeCabの準備\n","tagger = MeCab.Tagger()\n","# 学習済みモデルを読み出す\n","model = pickle.load(open(model_file, \"rb\"))\n","\n","# テキストがスパムかどうか判定する\n","def check_spam(text):\n","    # テキストを単語IDのリストに変換し単語の頻出頻度を調べる\n","    zw = np.zeros(word_dic['__id'])\n","    count = 0\n","    s = tagger.parse(text)\n","    # 単語毎の回数を加算\n","    for line in s.split(\"\\n\"):\n","        if line == \"EOS\": break\n","        org = line.split('\\t')[1].split(',')[6]\n","        if org in word_dic:\n","            id = word_dic[org]\n","            zw[id] += 1\n","            count += 1\n","    zw = zw / count\n","    # 予測\n","    pre = model.predict([zw])[0]\n","    print(\"- 結果=\", label_names[pre])"],"metadata":{"id":"qnVJCy7S6rK_","colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"status":"error","timestamp":1654824962495,"user_tz":-540,"elapsed":250,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}},"outputId":"a9e9a685-2874-42f9-a448-1f07eca5b888"},"id":"qnVJCy7S6rK_","execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-250bee3b3e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 学習済みモデルを読み出す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# テキストがスパムかどうか判定する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ok-spam-model.pickle'"]}]},{"cell_type":"code","source":["check_spam(test_text1)\n","check_spam(test_text2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"nYeNwVrE7NK_","outputId":"61110701-95d0-4cb4-f8f1-070d7efc622d","executionInfo":{"status":"error","timestamp":1654824966515,"user_tz":-540,"elapsed":238,"user":{"displayName":"黒崎輝","userId":"02350253156195984935"}}},"id":"nYeNwVrE7NK_","execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-ad0ab8f0348b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_spam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcheck_spam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'check_spam' is not defined"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"0610_spammail.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}